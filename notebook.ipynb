{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Load Libraries & Datasets","metadata":{"id":"xitJD8if4Biq"}},{"cell_type":"code","source":"import os, io, gc\nimport numpy as np\nimport pandas as pd\nimport random\n\nfrom scipy.fft import fft\nfrom scipy.signal import hilbert, blackman\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.model_selection import KFold\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.layers import Input, Dense, Dropout, Activation\nfrom tensorflow.keras.layers import Add, concatenate\nfrom tensorflow.keras.layers import Bidirectional, LSTM\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.utils import plot_model\nfrom tensorflow.keras.models import Model, Sequential, load_model\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n\nimport matplotlib.pyplot as plt\npd.set_option('display.max_columns',None)\n\nimport warnings\nwarnings.filterwarnings('ignore')\ngc.enable()","metadata":{"id":"taGsbb9W3-R7","execution":{"iopub.status.busy":"2022-02-16T20:45:01.9008Z","iopub.execute_input":"2022-02-16T20:45:01.901225Z","iopub.status.idle":"2022-02-16T20:45:07.721647Z","shell.execute_reply.started":"2022-02-16T20:45:01.90113Z","shell.execute_reply":"2022-02-16T20:45:07.720871Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"SEED = 42\ndef seed_everything(seed=SEED):\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    random.seed(seed)\n    tf.random.set_seed(seed)\nseed_everything()","metadata":{"id":"YinWgn6q3-SC","execution":{"iopub.status.busy":"2022-02-16T20:45:07.739393Z","iopub.execute_input":"2022-02-16T20:45:07.74008Z","iopub.status.idle":"2022-02-16T20:45:07.754778Z","shell.execute_reply.started":"2022-02-16T20:45:07.74004Z","shell.execute_reply":"2022-02-16T20:45:07.754148Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv('../input/ventilator-pressure-prediction/train.csv')\ntest_df = pd.read_csv('../input/ventilator-pressure-prediction/test.csv')\nsubmission_df = pd.read_csv('../input/ventilator-pressure-prediction/sample_submission.csv')","metadata":{"id":"htIChQRR3-SE","execution":{"iopub.status.busy":"2022-02-16T20:45:07.756411Z","iopub.execute_input":"2022-02-16T20:45:07.756732Z","iopub.status.idle":"2022-02-16T20:45:22.693104Z","shell.execute_reply.started":"2022-02-16T20:45:07.756707Z","shell.execute_reply":"2022-02-16T20:45:22.692479Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pressure_unique = np.sort(train_df['pressure'].unique())\nlen_pressure = len(pressure_unique)\nPRESSURE_MIN = pressure_unique[0].item()\nPRESSURE_MAX = pressure_unique[-1].item()\nPRESSURE_STEP = (pressure_unique[1] - pressure_unique[0]).item()","metadata":{"id":"3oCUocXbBCxP","execution":{"iopub.status.busy":"2022-02-16T20:45:22.694086Z","iopub.execute_input":"2022-02-16T20:45:22.69472Z","iopub.status.idle":"2022-02-16T20:45:22.774444Z","shell.execute_reply.started":"2022-02-16T20:45:22.694689Z","shell.execute_reply":"2022-02-16T20:45:22.773803Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Processing","metadata":{"id":"EQ8pp-z23-SE"}},{"cell_type":"code","source":"def feature_processing(df, backward_sequence=False):\n    \n    feature_list_1 = ['time_step', 'u_in', 'u_out']\n    feature_list_2 = ['u_in', 'u_out']\n    \n    ###########################################################################\n\n    # backward sequence\n    if backward_sequence:\n        df['rank'] = df.groupby(['breath_id'])['time_step'].rank()\n        df['neg_rank'] = -1 * df['rank']\n        df = df.sort_values(by=['breath_id','neg_rank']).reset_index(drop=True)\n        del df['rank'],df['neg_rank']\n        gc.collect()\n    \n    ###########################################################################\n\n    df['one'] = 1\n    df['count'] = (df['one']).groupby(df['breath_id']).cumsum()\n    \n    df['u_in_cumsum'] = df.groupby(['breath_id'])['u_in'].cumsum()\n    df['u_in_cummean'] = df['u_in_cumsum'] / df['count']\n    \n    del df['one'], df['count']\n    gc.collect()\n    \n    ###########################################################################\n    \n    # cross, delta & area\n\n    df['log_u_in'] = np.log1p(df['u_in'])\n    df[\"cross_u_in\"] = df[\"u_in\"] * (1 - df[\"u_out\"])\n    df[\"cross_time_step\"] = df[\"time_step\"] * (1 - df[\"u_out\"])\n    \n    df['cross_1']= df['u_in'] * df['u_out']\n    df['cross_2']= df['time_step'] * df['u_out']\n    \n    df[\"area_frac\"] = df[\"u_in\"] * df[\"time_step\"]\n    df[\"cross_area_frac\"] = df[\"area_frac\"] * (1 - df[\"u_out\"])\n    df[\"area_frac_cumsum\"] = df.groupby(['breath_id'])[\"area_frac\"].cumsum()\n    \n    df['time_gap'] = df['time_step'] - df.shift(1).fillna(0)['time_step']\n    df['u_in_gap'] = df['u_in'] - df.shift(1).fillna(0)['u_in']\n    df['u_in_rate'] = df['u_in_gap'] / df['time_gap']\n    \n    df.loc[list(range(0, len(df), 80)), 'time_gap'] = 0\n    df.loc[list(range(0, len(df), 80)), 'u_in_gap'] = 0\n    df.loc[list(range(0, len(df), 80)), 'u_in_rate'] = 0\n    \n    df['area_1'] = df['u_in'] * df['time_step']\n    df['area_2'] = df['u_in'] * df['time_gap']\n    df['area_timestep_cumsum'] = df.groupby(['breath_id'])['area_1'].cumsum()\n        \n    df['air_flow_rate'] = df['u_out'] - (df['u_in']/100)\n    df['air_flow_area'] = df['air_flow_rate'] * df['time_step']\n    \n    df['time_step_diff_1'] = df.groupby(['breath_id'])['time_step'].diff(1).fillna(0)\n    df['time_step_diff_1_r'] = df.groupby(['breath_id'])['time_step'].diff(-1).fillna(0)\n    \n    df['delta_1'] = df['time_step_diff_1'] * df['u_in']\n    df['delta_2'] = df['time_step_diff_1_r'] * df['u_in']\n    \n    df['area_1'] = df.groupby(['breath_id'])['delta_1'].cumsum()\n    df['area_2'] = df.groupby(['breath_id'])['delta_2'].cumsum()\n    df['area_delta_cumsum'] = df.groupby(['breath_id'])['area_1'].cumsum()\n    \n    df['max_to_cumsum_u_in_per_breath_id'] = df.groupby(['breath_id'])['u_in'].transform('max') - df['u_in_cumsum']\n    \n    ###########################################################################\n    \n    # vf: approximation for rate of change in volume at a particular time stamp\n    # vt: approximation for total lungs volume at a particular time stamp\n    # source: https://www.kaggle.com/c/ventilator-pressure-prediction/discussion/281299\n    \n    df['vt'] = 0\n    df['exponent'] = (-df['time_step']) / (df['R'] * df['C']) \n    df['factor'] = np.exp(df['exponent'])\n    df['v1'] = (df['u_in'] * df['R']) / df['factor']\n    df['vf'] = (df['u_in_cumsum'] * df['R']) / df['factor']\n    df.loc[df['time_step'] != 0, 'vt'] = df['area_timestep_cumsum']/(df['C'] * (1 - df['factor']))\n    df['v'] = df['vf'] + df['vt']\n        \n    ###########################################################################\n    \n    # lags, difference, and rolling\n    \n    lags = 3\n    for lag in range(1, lags+1):\n        for feature in feature_list_1:\n            ## lag \n            df[f'{feature}_lag_{lag}'] = df.groupby(['breath_id'])[feature].shift(lag).fillna(0)\n            ## inverse lag\n            df[f'{feature}_lag_inverse_{lag}'] = df.groupby(['breath_id'])[feature].shift(-lag).fillna(0)\n            ## diff lag\n            # df[f'{feature}_lag_diff_{lag}'] = df[feature] - df[f'{feature}_lag_{lag}']\n            # df[f'{feature}_lag_diff_{lag}'] = df[f'{feature}_lag_diff_{lag}'].fillna(0)\n            ## diff inverse lag\n            # df[f'{feature}_lag_inverse_diff_{lag}'] = df[feature] - df[f'{feature}_lag_inverse_{lag}']\n    \n    diff = 3\n    for diff in range(1, diff+1):\n        df[f'u_in_diff_{diff}'] = df.groupby(['breath_id'])['u_in'].diff(diff).fillna(0)\n\n    # df['u_in_diff_1'] = df.groupby(['breath_id'])['u_in'].diff(1).fillna(0)\n    \n    \"\"\"\n    lags = 3\n    for lag in range(1, lags+1):\n        for feature in feature_list_2:\n            # breath_id lag \n            df[f'breath_id_lag_{lag}'] = df['breath_id'].shift(lag).fillna(0)\n            # breath_id same lag\n            df[f'breath_id_lag_{lag}_same'] = np.select([df[f'breath_id_lag_{lag}'] == df['breath_id']],[1],0)\n            # breath_id and feature_list_2\n            df[f'breath_id_{feature}_lag_{lag}'] = df[feature].shift(lag).fillna(0)\n            df[f'breath_id_{feature}_lag_{lag}'] = df[f'breath_id_{feature}_lag_{lag}'] * df[f'breath_id_lag_{lag}_same']\n            del df[f'breath_id_lag_{lag}_same'], df[f'breath_id_{feature}_lag_{lag}']\n    \"\"\"\n    df['mean_u_out_per_breath_id'] = df.groupby(['breath_id'])['u_out'].transform('mean')\n    df['breath_id_u_in_max'] = df.groupby(['breath_id'])['u_in'].transform('max')\n    df['breath_id_u_in_diff_max'] = df.groupby(['breath_id'])['u_in'].transform('max') - df['u_in']\n    df['breath_id_u_in_diff_max'] = df.groupby(['breath_id'])['u_in'].transform('mean') - df['u_in']\n    \n    \"\"\" \n    windows = [8, 16, 32]\n    for feature in feature_list_:\n        for window in windows:\n            df[f'{feature}_rolling_mean_{window}'] = df.groupby('breath_id')[feature].rolling(window).mean().reset_index(drop=True)\n            df[f'{feature}_rolling_min_{window}'] = df.groupby('breath_id')[feature].rolling(window).min().reset_index(drop=True)\n            df[f'{feature}_rolling_max_{window}'] = df.groupby('breath_id')[feature].rolling(window).max().reset_index(drop=True)\n            df[f'{feature}_rolling_std_{window}'] = df.groupby('breath_id')[feature].rolling(window).std().reset_index(drop=True)\n            df[f'{feature}_rolling_std_{window}'] = df.groupby('breath_id')[feature].rolling(window).sum().reset_index(drop=True)\n    \"\"\"\n        \n    ###########################################################################\n    \n    # Features based on aggregations over R, C, rank and rounded u_in value (f1 - f6)\n    # Source: https://www.kaggle.com/l0glikelihood/0-1093-single-public-lb\n    \n    df['sum_per_breath'] = df.groupby(['breath_id'])['u_in'].transform('sum')\n    df['rounded_u_in'] = df['u_in'].round(0)\n    df['rank'] = df.groupby(['breath_id'])['time_step'].rank()\n    df['uid'] = df['R'].astype(str)+'_' + df['C'].astype(str) + '_' + df['rounded_u_in'].astype(str) + '_' + df['rank'].astype(str)\n\n    # max, min, mean, count values of u_in for each uid\n    df['uid_count'] = df.groupby(['uid'])['uid'].transform('count') \n    df['f1'] = df.groupby(['uid'])['u_in'].transform('mean')\n    df['f2'] = df.groupby(['uid'])['u_in'].transform('min')\n    df['f3'] = df.groupby(['uid'])['u_in'].transform('max')\n\n    # difference between the current value of u_in and its mean, min and max values within the uid\n    df['f4'] = df['u_in'] - df.groupby(['uid'])['u_in'].transform('mean')\n    df['f5'] = df['u_in'] - df.groupby(['uid'])['u_in'].transform('min')\n    df['f6'] = df['u_in'] - df.groupby(['uid'])['u_in'].transform('max')\n    \n    del df['rounded_u_in'],df['rank'],df['uid']\n        \n    ###########################################################################\n    \n    \"\"\"\n    # spectral features\n    # source: https://www.kaggle.com/lucasmorin/spectral-analysis-feature-engineering\n    \n    ffta = lambda x: np.abs(fft(np.append(x.values,x.values[0]))[:80])\n    ffta.__name__ = 'ffta'\n\n    fftw = lambda x: np.abs(fft(np.append(x.values,x.values[0])*w)[:80])\n    fftw.__name__ = 'fftw'\n\n    N = 80\n    w = blackman(N+1)\n\n    df['fft_u_in'] = df.groupby('breath_id')['u_in'].transform(ffta)\n    df['fft_u_in_w'] = df.groupby('breath_id')['u_in'].transform(fftw)\n    df['analytical'] = df.groupby('breath_id')['u_in'].transform(hilbert)\n    df['envelope'] = np.abs(df['analytical'])\n    df['phase'] = np.angle(df['analytical'])\n    df['unwrapped_phase'] = df.groupby('breath_id')['phase'].transform(np.unwrap)\n    df['phase_shift1'] = df.groupby('breath_id')['unwrapped_phase'].shift(1).astype(np.float32)\n    df['IF'] = df['unwrapped_phase'] - df['phase_shift1'].astype(np.float32)\n    df = df.fillna(0)\n    \n    del df['analytical']\n    \"\"\"\n    \n    ###########################################################################\n    \n    # R and C features\n    \n    df['R_u_in'] = df['u_in'] * df['R']\n    df['C_u_in'] = df['u_in'] * df['C']\n    \n    # mean u_in per R, C, and u_out\n    df['mean_u_in_per_R_C_u_out'] = df.groupby(['R','C','u_out'])['u_in'].transform('mean')\n    df['diff_mean_u_in_per_R_C_u_out'] = df['u_in'] - df['mean_u_in_per_R_C_u_out']\n    df['to_mean_u_in_per_R_C_u_out'] = df.groupby(['breath_id'])['u_in'].transform('mean') - df['mean_u_in_per_R_C_u_out']\n    \n    # max value of u_in grouped by R, C, and u_out\n    df['max_u_in_per_R_C_u_out'] = df.groupby(['R','C','u_out'])['u_in'].transform('max')\n    df['diff_max_u_in_per_R_C_u_out'] = df['u_in'] - df['max_u_in_per_R_C_u_out']\n    df['to_max_u_in_per_R_C_u_out'] = df.groupby(['breath_id'])['u_in'].transform('max') - df['max_u_in_per_R_C_u_out']\n    \n    # OHE\n    df['R'] = df['R'].astype(str)\n    df['C'] = df['C'].astype(str)\n    df['R_C'] = df['R'].astype(str) + '_' + df['C'].astype(str)\n    df = pd.get_dummies(df)\n    \n    ###########################################################################\n        \n    return df","metadata":{"id":"0ce1wm863-SG","execution":{"iopub.status.busy":"2022-02-16T20:45:22.77552Z","iopub.execute_input":"2022-02-16T20:45:22.776037Z","iopub.status.idle":"2022-02-16T20:45:22.82401Z","shell.execute_reply.started":"2022-02-16T20:45:22.776003Z","shell.execute_reply":"2022-02-16T20:45:22.823206Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.concat([train_df,test_df],axis=0,copy=False).reset_index(drop=True)\ndf = feature_processing(df)\n    \ntrain = df.iloc[:len(train_df),:]\ntest = df.iloc[len(train_df):,:].reset_index(drop=True)\n    \ndel df, train_df, test_df\ndel test['pressure']\ngc.collect()","metadata":{"id":"a_eWMpFe3-SN","outputId":"371e0870-4bae-42b6-f62f-5bebf17e002c","execution":{"iopub.status.busy":"2022-02-16T20:45:22.82514Z","iopub.execute_input":"2022-02-16T20:45:22.825405Z","iopub.status.idle":"2022-02-16T20:50:10.780766Z","shell.execute_reply.started":"2022-02-16T20:45:22.825379Z","shell.execute_reply":"2022-02-16T20:50:10.779395Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = train.copy()\ntargets = train[['pressure']].to_numpy().reshape(-1, 80)\ntrain.drop(['pressure','id', 'breath_id'], axis=1, inplace=True)\nu_outs = train[['u_out']].to_numpy().reshape(-1, 80)\ntest = test.drop(['id', 'breath_id'], axis=1)","metadata":{"id":"ERBdSjPo3-SQ","execution":{"iopub.status.busy":"2022-02-16T20:50:10.790705Z","iopub.execute_input":"2022-02-16T20:50:10.79141Z","iopub.status.idle":"2022-02-16T20:50:16.455987Z","shell.execute_reply.started":"2022-02-16T20:50:10.79133Z","shell.execute_reply":"2022-02-16T20:50:16.455359Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Scaler\nRS = RobustScaler(quantile_range=(20.0, 80.0))\nRS.fit(train[train['u_out']==0])\n\ntrain = RS.fit_transform(train)\ntest = RS.transform(test)\n\ntrain = train.reshape(-1, 80, train.shape[-1])\ntest = test.reshape(-1, 80, train.shape[-1])","metadata":{"id":"1l4q6AYX3-SS","execution":{"iopub.status.busy":"2022-02-16T20:50:16.45891Z","iopub.execute_input":"2022-02-16T20:50:16.459163Z","iopub.status.idle":"2022-02-16T20:50:40.591261Z","shell.execute_reply.started":"2022-02-16T20:50:16.459134Z","shell.execute_reply":"2022-02-16T20:50:40.590248Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"train: {train.shape} \\ntest: {test.shape} \\ntargets: {targets.shape} \\nu_outs: {u_outs.shape}\")","metadata":{"id":"blV0aRkwBCxf","execution":{"iopub.status.busy":"2022-02-16T20:50:40.595654Z","iopub.execute_input":"2022-02-16T20:50:40.595963Z","iopub.status.idle":"2022-02-16T20:50:40.601219Z","shell.execute_reply.started":"2022-02-16T20:50:40.595925Z","shell.execute_reply":"2022-02-16T20:50:40.600501Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gc.collect()","metadata":{"id":"5F6v_ojG3-SS","execution":{"iopub.status.busy":"2022-02-16T20:50:40.602096Z","iopub.execute_input":"2022-02-16T20:50:40.60265Z","iopub.status.idle":"2022-02-16T20:50:40.782339Z","shell.execute_reply.started":"2022-02-16T20:50:40.602607Z","shell.execute_reply":"2022-02-16T20:50:40.781466Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ResBiLSTM Model","metadata":{"id":"s3_fcyGS3-SU"}},{"cell_type":"code","source":"# Accelerator Configuration\ntry:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)\n    BATCH_SIZE = tpu_strategy.num_replicas_in_sync * 64\n    print(\"Running on TPU:\", tpu.master())\n    print(f\"Batch Size: {BATCH_SIZE}\")\n    \nexcept ValueError:\n    strategy = tf.distribute.get_strategy()\n    BATCH_SIZE = 512\n    print(f\"Running on {strategy.num_replicas_in_sync} replicas\")\n    print(f\"Batch Size: {BATCH_SIZE}\")","metadata":{"id":"dPuUjWPbBCxh","execution":{"iopub.status.busy":"2022-02-16T20:50:40.783678Z","iopub.execute_input":"2022-02-16T20:50:40.783961Z","iopub.status.idle":"2022-02-16T20:50:46.956348Z","shell.execute_reply.started":"2022-02-16T20:50:40.783925Z","shell.execute_reply":"2022-02-16T20:50:46.955655Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Model Configuration\nclass CFG:\n    seed = 42\n    VERBOSE = 1\n    random_state = 42\n    N_FOLDS = 5\n    EPOCHS = 200\n    BATCH_SIZE = BATCH_SIZE\n    factor = 0.5\n    patience_1 = 5\n    patience_2 = 15\n    learning_rate = 1e-3\n    weight_decay = 1e-3\n    dropout_rate = 0.2","metadata":{"id":"5bXAQLW13-SU","execution":{"iopub.status.busy":"2022-02-16T20:50:46.958165Z","iopub.execute_input":"2022-02-16T20:50:46.959421Z","iopub.status.idle":"2022-02-16T20:50:46.964671Z","shell.execute_reply.started":"2022-02-16T20:50:46.959385Z","shell.execute_reply":"2022-02-16T20:50:46.963771Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Custom MAE Loss\ndef custom_mae_loss(y_true, y_pred, n=80):\n    u_out = y_true[:, n: ]\n    y = y_true[:, :n ]\n    w = 1 - u_out\n    mae = w * tf.abs(y - y_pred)\n    return tf.reduce_sum(mae, axis=-1) / tf.reduce_sum(w, axis=-1)","metadata":{"id":"nYDBSrD5DdhK","execution":{"iopub.status.busy":"2022-02-16T20:50:46.96583Z","iopub.execute_input":"2022-02-16T20:50:46.966031Z","iopub.status.idle":"2022-02-16T20:50:46.976456Z","shell.execute_reply.started":"2022-02-16T20:50:46.966008Z","shell.execute_reply":"2022-02-16T20:50:46.975888Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def dnn_model():\n    x_input = Input(shape=(train.shape[-2:]))\n    \n    x1 = Bidirectional(LSTM(units=1024, return_sequences=True))(x_input)\n    c1 = concatenate([x_input, x1])\n    \n    x2 = Bidirectional(LSTM(units=512, return_sequences=True))(c1)\n    c2 = concatenate([x1, x2])\n    \n    x3 = Bidirectional(LSTM(units=256, return_sequences=True))(c2)\n    c3 = concatenate([x2, x3])\n    \n    x4 = Bidirectional(LSTM(units=128, return_sequences=True))(c3)\n    c4 = concatenate([x3, x4])\n    \n    x5 = Dense(units=128, activation='selu')(c4)\n    x_output = Dense(units=1)(x5)\n    \n    model = Model(inputs=x_input, outputs=x_output, name='DNN_Model')\n    model.compile(optimizer='Adam', loss=custom_mae_loss)\n    \n    return model","metadata":{"id":"kX3AmT6f3-SV","execution":{"iopub.status.busy":"2022-02-16T20:50:46.977424Z","iopub.execute_input":"2022-02-16T20:50:46.977612Z","iopub.status.idle":"2022-02-16T20:50:46.987091Z","shell.execute_reply.started":"2022-02-16T20:50:46.97759Z","shell.execute_reply":"2022-02-16T20:50:46.986528Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = dnn_model()\nmodel.summary()","metadata":{"id":"6CFobPCv3-SV","execution":{"iopub.status.busy":"2022-02-16T20:50:46.990146Z","iopub.execute_input":"2022-02-16T20:50:46.990387Z","iopub.status.idle":"2022-02-16T20:50:51.274324Z","shell.execute_reply.started":"2022-02-16T20:50:46.990363Z","shell.execute_reply":"2022-02-16T20:50:51.273397Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_model(model, to_file='dnn_model.png', show_shapes=True, show_layer_names=True)","metadata":{"id":"w3mqfZ5p3-SV","execution":{"iopub.status.busy":"2022-02-16T20:50:51.275578Z","iopub.execute_input":"2022-02-16T20:50:51.275826Z","iopub.status.idle":"2022-02-16T20:50:52.296253Z","shell.execute_reply.started":"2022-02-16T20:50:51.275798Z","shell.execute_reply":"2022-02-16T20:50:52.295286Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_preds = []\nhistory_list = []\noof_true = []\noof_pred = []","metadata":{"id":"WeyYFqPFBCxj","execution":{"iopub.status.busy":"2022-02-16T20:50:52.2977Z","iopub.execute_input":"2022-02-16T20:50:52.29793Z","iopub.status.idle":"2022-02-16T20:50:52.302508Z","shell.execute_reply.started":"2022-02-16T20:50:52.2979Z","shell.execute_reply":"2022-02-16T20:50:52.301784Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with tpu_strategy.scope():\n    kf = KFold(n_splits=CFG.N_FOLDS, shuffle=True, random_state=42)\n    oof_preds = np.zeros((train.shape[0],train.shape[1]))\n\n    for fold, (train_idx, test_idx) in enumerate(kf.split(train, targets)):\n        print('='*25, '>', f'Fold {fold+1}', '<', '='*25)\n        \n        checkpoint_filepath = f'fold{fold+1}.hdf5'\n        X_train, X_valid = train[train_idx], train[test_idx]\n        y_train, y_valid = targets[train_idx], targets[test_idx]\n        u_out_train, u_out_valid = u_outs[train_idx], u_outs[test_idx] \n            \n        lr = ReduceLROnPlateau(monitor=\"val_loss\", factor=CFG.factor, patience=CFG.patience_1,\n                               verbose=CFG.VERBOSE)\n        es = EarlyStopping(monitor=\"val_loss\", patience=CFG.patience_2, mode=\"min\",\n                           restore_best_weights=True, verbose=CFG.VERBOSE)\n        sv = ModelCheckpoint(checkpoint_filepath, monitor = 'val_loss', verbose = CFG.VERBOSE,\n                             save_best_only = True, save_weights_only = True, mode = 'min')\n        \n        model = dnn_model()\n        history = model.fit(X_train, np.append(y_train, u_out_train, axis =1),\n                            validation_data=(X_valid, np.append(y_valid, u_out_valid, axis =1)),\n                            epochs=CFG.EPOCHS, batch_size=CFG.BATCH_SIZE, callbacks=[lr,es,sv])        \n        history_list += [history]\n        \n        # predict oof\n        y_pred = model.predict(X_valid)\n        y_true = y_valid.squeeze().reshape(-1, 1)\n\n        ## inspiratory and expiratory phases\n        score = mean_absolute_error(y_true, y_pred.squeeze().reshape(-1, 1))\n        print(f'Fold {fold+1} | Overall MAE Score: {score}')\n        \n        ## inspiratory phase\n        oof_true.append(y_true)\n        oof_pred.append(y_pred.squeeze().reshape(-1, 1))\n        oof_preds[test_idx] = y_pred.reshape(y_pred.shape[0],y_pred.shape[1])\n        reshaped_targets = targets.squeeze().reshape(-1,1).squeeze()\n        \n        score = mean_absolute_error(reshaped_targets,oof_preds.squeeze().reshape(-1,1).squeeze())\n        print(f'Fold {fold+1} | Inspiratory MAE Score: {score}')\n        \n        # predict test\n        test_preds.append(model.predict(test).squeeze().reshape(-1, 1).squeeze())\n        del X_train, X_valid, y_train, y_valid\n        gc.collect()\n        \n    np.save('test_preds.npy', test_preds)","metadata":{"id":"DL8XNBZXBCxk","execution":{"iopub.status.busy":"2022-02-16T20:50:52.303871Z","iopub.execute_input":"2022-02-16T20:50:52.304095Z","iopub.status.idle":"2022-02-17T00:53:05.62386Z","shell.execute_reply.started":"2022-02-16T20:50:52.304068Z","shell.execute_reply":"2022-02-17T00:53:05.622197Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"oof_preds = oof_preds.squeeze().reshape(-1,1).squeeze()\nreshaped_targets = targets.squeeze().reshape(-1,1).squeeze()\nscore = mean_absolute_error(reshaped_targets, oof_preds)\nprint(f'Overall OOF MAE Score: {score}')","metadata":{"id":"UeaMNbnXBCxk","execution":{"iopub.status.busy":"2022-02-17T00:53:05.625799Z","iopub.execute_input":"2022-02-17T00:53:05.626108Z","iopub.status.idle":"2022-02-17T00:53:05.731844Z","shell.execute_reply.started":"2022-02-17T00:53:05.626062Z","shell.execute_reply":"2022-02-17T00:53:05.730749Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"idx = train_df[train_df['u_out']==0].index\ntrain_df['prediction'] = oof_preds\nscore = mean_absolute_error(train_df.loc[idx,'pressure'],train_df.loc[idx,'prediction'])\nprint(f'Training Inspiratory MAE Score: {score}')","metadata":{"id":"OBGpS4jADdhM","execution":{"iopub.status.busy":"2022-02-17T00:53:05.733017Z","iopub.execute_input":"2022-02-17T00:53:05.733267Z","iopub.status.idle":"2022-02-17T00:53:09.019053Z","shell.execute_reply.started":"2022-02-17T00:53:05.733229Z","shell.execute_reply":"2022-02-17T00:53:09.018045Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"idx = train_df[train_df['u_out']==1].index\ntrain_df['prediction'] = oof_preds\nscore = mean_absolute_error(train_df.loc[idx,'pressure'],train_df.loc[idx,'prediction'])\nprint(f'Training Expiratory MAE Score: {score}')","metadata":{"id":"Z50PD4eoDdhM","execution":{"iopub.status.busy":"2022-02-17T00:53:09.020458Z","iopub.execute_input":"2022-02-17T00:53:09.020767Z","iopub.status.idle":"2022-02-17T00:53:11.26132Z","shell.execute_reply.started":"2022-02-17T00:53:09.020734Z","shell.execute_reply":"2022-02-17T00:53:11.260374Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"t = 0\nfor k in range(CFG.N_FOLDS):\n    mae = np.mean(np.abs(oof_pred[k] - oof_true[k]))\n    t += mae\n    print(f'Fold {k+1} | MAE Validation Score: {mae}')\nprint(f'Overall CV MAE: {t/CFG.N_FOLDS}')","metadata":{"id":"nAUcnBTNBCxk","execution":{"iopub.status.busy":"2022-02-17T00:53:11.262898Z","iopub.execute_input":"2022-02-17T00:53:11.263407Z","iopub.status.idle":"2022-02-17T00:53:11.304827Z","shell.execute_reply.started":"2022-02-17T00:53:11.26336Z","shell.execute_reply":"2022-02-17T00:53:11.303924Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"t = 0\nfor k in range(CFG.N_FOLDS):\n    mae = np.mean(np.abs(oof_preds[k] - oof_true[k]))\n    t += mae\n    print(f'Fold {k+1} | Inspiratory MAE Score: {mae}')\nprint(f'Overall Inspiratory MAE Score: {t/CFG.N_FOLDS}')","metadata":{"id":"Mk8ARRsYDdhM","execution":{"iopub.status.busy":"2022-02-17T00:53:11.30651Z","iopub.execute_input":"2022-02-17T00:53:11.307105Z","iopub.status.idle":"2022-02-17T00:53:11.402339Z","shell.execute_reply.started":"2022-02-17T00:53:11.307047Z","shell.execute_reply":"2022-02-17T00:53:11.401378Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_hist(hist, with_grid=True):\n    plt.figure(figsize=(20,5))\n    for i in range(len(hist)):\n        plt.plot(hist[i].history[\"loss\"], color='grey')\n        plt.plot(hist[i].history[\"val_loss\"], color='green')\n    plt.title(\"\")\n    plt.ylabel(\"Mean Absolute Error\")\n    plt.xlabel(\"epoch\")\n    plt.legend([\"Training\", \"Validation\"], loc=\"upper right\")\n    if with_grid:\n        plt.grid(which='major', axis='both')\n    plt.show()\nplot_hist(history_list)","metadata":{"id":"jQD_DUIAKIzK","execution":{"iopub.status.busy":"2022-02-17T00:53:11.403642Z","iopub.execute_input":"2022-02-17T00:53:11.40397Z","iopub.status.idle":"2022-02-17T00:53:11.957008Z","shell.execute_reply.started":"2022-02-17T00:53:11.403938Z","shell.execute_reply":"2022-02-17T00:53:11.956104Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Post-Processing","metadata":{"id":"FWNOP1ShTAZL"}},{"cell_type":"code","source":"# Ensemble Folds with Mean\nsubmission_df['pressure'] = np.mean(np.vstack(test_preds),axis=0)\nsubmission_df.to_csv('submission_mean.csv', index=False)","metadata":{"id":"vMstZtY6NjOn","execution":{"iopub.status.busy":"2022-02-17T00:53:11.961013Z","iopub.execute_input":"2022-02-17T00:53:11.961289Z","iopub.status.idle":"2022-02-17T00:53:24.139667Z","shell.execute_reply.started":"2022-02-17T00:53:11.961257Z","shell.execute_reply":"2022-02-17T00:53:24.138617Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Ensemble Folds with Median\nsubmission_df['pressure'] = np.median(np.vstack(test_preds),axis=0)\nsubmission_df.to_csv('submission_median.csv', index=False)","metadata":{"id":"d-RFLZkhNg8x","execution":{"iopub.status.busy":"2022-02-17T00:53:24.14099Z","iopub.execute_input":"2022-02-17T00:53:24.141254Z","iopub.status.idle":"2022-02-17T00:53:36.617284Z","shell.execute_reply.started":"2022-02-17T00:53:24.141208Z","shell.execute_reply":"2022-02-17T00:53:36.616369Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Ensemble Folds with Median and Round Prediction\nsubmission_df['pressure'] = np.mean(np.vstack(test_preds),axis=0)\nsubmission_df['pressure'] = np.round((submission_df['pressure'] - PRESSURE_MIN)/PRESSURE_STEP) * PRESSURE_STEP + PRESSURE_MIN\nsubmission_df['pressure'] = np.clip(submission_df['pressure'], PRESSURE_MIN, PRESSURE_MAX)\nsubmission_df.to_csv('submission_median_round.csv', index=False)","metadata":{"id":"UcVFCiL5Nhkq","execution":{"iopub.status.busy":"2022-02-17T00:53:36.61902Z","iopub.execute_input":"2022-02-17T00:53:36.619345Z","iopub.status.idle":"2022-02-17T00:53:51.69866Z","shell.execute_reply.started":"2022-02-17T00:53:36.619305Z","shell.execute_reply":"2022-02-17T00:53:51.697812Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Nearest Neighbor Method\n## Mean\nsubmission_df['pressure'] = np.mean(np.vstack(test_preds),axis=0)\nsubmission_df['pressure'] = submission_df['pressure'].map(lambda x: pressure_unique[np.abs(pressure_unique - x).argmin()])\nsubmission_df.to_csv('submission_nn_mean.csv', index=False)\n\n## Median\nsubmission_df['pressure'] = np.median(np.vstack(test_preds),axis=0)\nsubmission_df['pressure'] = submission_df['pressure'].map(lambda x: pressure_unique[np.abs(pressure_unique - x).argmin()])\nsubmission_df.to_csv('submission_nn_median.csv', index=False)","metadata":{"id":"VEWRr34WBCxn","execution":{"iopub.status.busy":"2022-02-17T00:55:46.270349Z","iopub.execute_input":"2022-02-17T00:55:46.270555Z","iopub.status.idle":"2022-02-17T00:57:09.964777Z","shell.execute_reply.started":"2022-02-17T00:55:46.270531Z","shell.execute_reply":"2022-02-17T00:57:09.964034Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Mean-Median Method\n# Source: https://www.kaggle.com/c/ventilator-pressure-prediction/discussion/282735\n\ndef better_than_median(inputs, spread_lim = None, axis=0):\n    \"\"\"\n    Compute the mean of the predictions if there are no outliers,\n    or the median if there are outliers.\n\n    Parameter: inputs = ndarray of shape (n_samples, n_folds)\n    \"\"\"\n    spread = inputs.max(axis=axis) - inputs.min(axis=axis) \n    print(f\"Inliers:  {(spread < spread_lim).sum():7} -> compute mean\")\n    print(f\"Outliers: {(spread >= spread_lim).sum():7} -> compute median\")\n    print(f\"Total:    {len(inputs):7}\")\n    return np.where(spread < spread_lim,\n                    np.mean(inputs, axis=axis),\n                    np.median(inputs, axis=axis))\n\nsubmission_df['pressure'] = better_than_median(np.vstack(test_preds), spread_lim = 0.50)\nsubmission_df.to_csv('submission_mixed_50.csv', index=False)","metadata":{"id":"p05IgQGbNybA","execution":{"iopub.status.busy":"2022-02-17T00:54:19.923345Z","iopub.execute_input":"2022-02-17T00:54:19.923745Z","iopub.status.idle":"2022-02-17T00:55:46.267947Z","shell.execute_reply.started":"2022-02-17T00:54:19.923702Z","shell.execute_reply":"2022-02-17T00:55:46.267018Z"},"trusted":true},"execution_count":null,"outputs":[]}]}